{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```diff\n",
    "+ The following section provides an opportunity for the student to create a classifier model from scratch, and then modify it to improve performance.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, neighbors, metrics, grid_search, cross_validation\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "irisdf = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "irisdf['target'] = iris.target\n",
    "cmap = {0:'r', 1:'g', 2:'b' }\n",
    "irisdf['ctarget'] = irisdf.target.apply(lambda x: cmap[x])\n",
    "irisdf.plot('petal length (cm)', 'petal width (cm)', kind='scatter', c=irisdf.ctarget)\n",
    "print(irisdf.describe())\n",
    "\n",
    "def my_classifier(row):\n",
    "    if row['petal length (cm)'] < 2:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "predictions = irisdf.apply(my_classifier, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisdf['predictions'] = predictions\n",
    "\n",
    "print(float(len(irisdf[irisdf.target == irisdf.predictions])) / len(irisdf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starter Code\n",
    "\n",
    "Work on improving the classifier below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classifier(row):\n",
    "    if row['petal length (cm)'] < 2:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "predictions = irisdf.apply(my_classifier, axis=1)\n",
    "\n",
    "irisdf['predictions'] = predictions\n",
    "\n",
    "print(float(len(irisdf[irisdf.target == irisdf.predictions])) / len(irisdf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using distance: KNN implementation\n",
    "\n",
    "```diff\n",
    "+ The following section provides an opportunity for the student to implement an existing sklearn model - KNN, and then try adjusting its parameters.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x_train,x_test,y_train,y_test = cross_validation.train_test_split(iris.data,iris.target,test_size=0.3)\n",
    "\n",
    "# n_neighbors is our option in KNN. We'll tune this value to attempt to improve our prediction.\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "\n",
    "knn.fit(x_train, y_train)\n",
    "prediction = knn.predict(x_test)\n",
    "print(prediction)\n",
    "print(y_test)\n",
    "\n",
    "print(knn.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we see a change in performance when using the distance weight?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5, weights='') # add in the weights parameter here\n",
    "knn.fit(x_train, y_train)\n",
    "print(knn.predict(x_test))\n",
    "print(y_test)\n",
    "\n",
    "print(knn.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution to solving K\n",
    "```diff\n",
    "+ The following section provides an opportunity for the student to implement grid search (a central theme from the previous class) in order to find the optimal value for k, given this particular data set.\n",
    "```\n",
    "This is only one approach to the problem, but adding in the 'distance' parameter (instead of uniform) would only be additive. Note the code would need some editing to handle it properly if done in the grid search; alternatively, make the change directly in the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall: what's an effective way to create a numerical list in python?\n",
    "\n",
    "kf = cross_validation.KFold(len(irisdf), n_folds = 5)\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=neighbors.KNeighborsClassifier(),\n",
    "    param_grid=params,\n",
    "    cv=kf,\n",
    ")\n",
    "gs.fit(iris.data, iris.target)\n",
    "gs.grid_scores_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
