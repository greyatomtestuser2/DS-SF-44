{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integer/float division in Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using \"/\" for integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "-3\n"
     ]
    }
   ],
   "source": [
    "print(5/2)\n",
    "print(-5/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using \"/\" for floating point numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n",
      "-2.5\n"
     ]
    }
   ],
   "source": [
    "print(5.0/2)\n",
    "print(-5.0/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using floor division operator: “//”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "-3\n",
      "2.0\n",
      "-3.0\n"
     ]
    }
   ],
   "source": [
    "print(5//2)\n",
    "print(-5//2)\n",
    "print(5.0//2)\n",
    "print(-5.0//2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: How to use Pandas Pivot Tables\n",
    "- see [pandas_pivot.ipynb](./extra/pandas_pivot.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: What are the different types of cross validations we've covered and examples of use cases/how-to’s? \n",
    "- **K-fold**: the most popular method, much faster than exhaustive search\n",
    "- **LOO**: maximizes the statistical strength of your sample, computationally-intensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: Resampling vs. Hyperparameter Optimization\n",
    "\n",
    "**Resampling**: validating models by using random subsets\n",
    "\n",
    "- **Bootstrapping**: any test or metric that relies on random sampling with replacement\n",
    "allows assigning measures of accuracy to sample estimates\n",
    "\n",
    "- **Cross validation**: assess how accurately a predictive model will perform in practice\n",
    "\n",
    "**Hyperparameter optimization**: find hyperparameters (e.g. regularization) that yield an optimal model which minimizes a predefined loss function on testing data\n",
    "\n",
    "- **Gridsearch**: an exhaustive searching through a manually specified subset of the hyperparameter space of a learning algorithm\n",
    "    - Manually tests cartesian product of all parameters\n",
    "\n",
    "- **Gradient-based**: compute the gradient with respect to hyperparameters and then optimize using gradient descent\n",
    "\n",
    "- **Cross-validation**: can be used to iteratively search single-parameter space\n",
    "    - But can also estimate the generalization of performance (resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background continued: Cross validation types\n",
    "\n",
    "**Non-exhaustive** cross-validation: do not compute all ways of splitting the original sample\n",
    "\n",
    "- E.g. **K-fold** cross-validation: the original sample is randomly partitioned into k equal sized subsamples\n",
    "\n",
    "**Exhaustive** cross-validation: learn and test on all possible ways to divide the original sample into a training and a validation set\n",
    "\n",
    "- E.g. **Leave-one-out** cross-validation (**LOO**): 1 observation is used as the validation set and the remaining observations as the training set\n",
    "    - This is repeated _n_ times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: K-fold cross validation where k=5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dat-44pt/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "import timeit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, metrics, cross_validation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Load data\n",
    "wd = './datasets/'\n",
    "bikeshare = pd.read_csv(wd + 'bikeshare.csv')\n",
    "\n",
    "weather = pd.get_dummies(bikeshare.weathersit, prefix='weather')\n",
    "modeldata = bikeshare[['temp', 'hum']].join(weather[['weather_1', 'weather_2', 'weather_3']])\n",
    "y = bikeshare.casual\n",
    "\n",
    "# Subset data\n",
    "modeldata = modeldata.iloc[:1000]\n",
    "y = y.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ CROSS VALIDATION each fold ~~~~\n",
      "('Model', 1)\n",
      "('MSE:', 28.27620266309812)\n",
      "('Model', 2)\n",
      "('MSE:', 47.35493495124778)\n",
      "('Model', 3)\n",
      "('MSE:', 52.65685958976694)\n",
      "('Model', 4)\n",
      "('MSE:', 40.61401109376968)\n",
      "('Model', 5)\n",
      "('MSE:', 35.374175824447)\n",
      "~~~~ SUMMARY OF CROSS VALIDATION ~~~~\n",
      "('Mean of MSE for all folds:', 40.855236824465905)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34891295433044434"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kfold_example():\n",
    "    kf = cross_validation.KFold(len(modeldata), n_folds=5, shuffle=True)\n",
    "\n",
    "    mse_values = []\n",
    "    scores = []\n",
    "    n= 0\n",
    "    print(\"~~~~ CROSS VALIDATION each fold ~~~~\")\n",
    "    for train_index, test_index in kf:\n",
    "        lm = linear_model.LinearRegression().fit(modeldata.iloc[train_index], y.iloc[train_index])\n",
    "        mse_values.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(modeldata.iloc[test_index])))\n",
    "        scores.append(lm.score(modeldata, y))\n",
    "        n += 1\n",
    "        print('Model', n)\n",
    "        print('MSE:', mse_values[n-1])\n",
    "\n",
    "    print(\"~~~~ SUMMARY OF CROSS VALIDATION ~~~~\")\n",
    "    print('Mean of MSE for all folds:', np.mean(mse_values))\n",
    "    \n",
    "timeit.timeit(kfold_example, number=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: LOO cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ SUMMARY OF CROSS VALIDATION ~~~~\n",
      "('Mean of MSE for all folds:', 40.77255321693947)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.128749132156372"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loo_example():\n",
    "    kf = cross_validation.KFold(len(modeldata), n_folds=len(modeldata), shuffle=False)\n",
    "\n",
    "    mse_values = []\n",
    "    scores = []\n",
    "\n",
    "    for train_index, test_index in kf:\n",
    "        lm = linear_model.LinearRegression().fit(modeldata.iloc[train_index], y.iloc[train_index])\n",
    "        mse_values.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(modeldata.iloc[test_index])))\n",
    "        scores.append(lm.score(modeldata, y))\n",
    "\n",
    "    print(\"~~~~ SUMMARY OF CROSS VALIDATION ~~~~\")\n",
    "    print('Mean of MSE for all folds:', np.mean(mse_values))\n",
    "\n",
    "timeit.timeit(loo_example, number=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: How do we use grid search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dat-44pt/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': array([-2.5       , -2.39795918, -2.29591837, -2.19387755, -2.09183673,\n",
      "       -1.98979592, -1.8877551 , -1.78571429, -1.68367347, -1.58163265,\n",
      "       -1.47959184, -1.37755102, -1.2755102 , -1.17346939, -1.07142857,\n",
      "       -0.96938776, -0.86734694, -0.76530612, -0.66326531, -0.56122449,\n",
      "       -0.45918367, -0.35714286, -0.25510204, -0.15306122, -0.05102041,\n",
      "        0.05102041,  0.15306122,  0.25510204,  0.35714286,  0.45918367,\n",
      "        0.56122449,  0.66326531,  0.76530612,  0.86734694,  0.96938776,\n",
      "        1.07142857,  1.17346939,  1.2755102 ,  1.37755102,  1.47959184,\n",
      "        1.58163265,  1.68367347,  1.78571429,  1.8877551 ,  1.98979592,\n",
      "        2.09183673,  2.19387755,  2.29591837,  2.39795918,  2.5       ])}\n",
      "-44.0098936054\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmcXGWd7/HPr6r3Tqc7C1nIHshCEpKAIWzKAEZZBsRdGGRYVNQBlRl1lItXvTOXO47jcsEZHcMIKiMgbsjMSBAQRw1LCJCETgKkk0C6k3Q6naT3ves3f9Tp0And6T7pqj7dVd/361WvOufUqVO/Yqlvn/M853nM3RERETmWWNQFiIjIyKewEBGRASksRERkQAoLEREZkMJCREQGpLAQEZEBKSxERGRACgsRERmQwkJERAaUE3UBqTJx4kSfPXt21GWIiIwqzz//fK27nzDQfhkTFrNnz2b9+vVRlyEiMqqY2euD2U+XoUREZEAKCxERGZDCQkREBqSwEBGRASksRERkQAoLEREZkMJCREQGlDH3WYgMN3entbOblo5uWju6Dy+3dHTR3pmgvStBZ3eCjp7nYDnhTneC4NlJuJNI9Jre2Cz5FKzGzIjHIBYz4mbEY8lHTszIicfIiRl5OTFyYjFy40ZuToz8eIz83Bh58XjwnFwvyIlTkBsnPydGLGZv/lIi/VBYiAAdXQn2NbRR29TOweaOIx4Hmjuoa+mksa2TxrYuGoLnxrZOEimcwt4MPIXHG0h+ToyC3DgFuTEKc+MU5uVQlBenKC8erMcpysuhOC9OUf5Rz3k5jMnPYUxBDmPy4xTn5yQfeTnEFUIZSWEhWaG+tZNdB1p4/WAzuw62sLeujeqGNqrr29hbnwyJvuTlxJhQnEdpYS5jC3M5sayQhQUllBTkMLYwlzH5yR/YgtzkD2hhXozC3BwKcmPk5cTIz4mRG08u58aTj5yYETMjFoO49Sz3/wPbnXjjDKQ74XS7093tdCWcrkSCrm6nozv53PsMpqMreXaTfO6mvStBW2c3bZ3Bc1c37Z2JI86K2jq7aW7vYn9jO62d3TS3d9Pa0UVzR/eg/1kX58WDEMlhTEEuJfk5lATrJQW5lBQk18ceXs5lbOGR63k5ukI+0igsJGMkEk7loRZeqW7k1X2NbKtp4rUDLew60Myhls4j9i0tzGVqaQFTSgtYMm0sU8YWMqU0nxNK8hlfnM+E4jzGFedRnBfHLNq/lHsuO0UpkXDaupLh0dLRRVN7F83tyWBpbO+iOXg0tiWfm4LtjW1dNLV1sq+hLbmtLfnaQApyY4wtyD0c0mODcC4tzGVsEC6lhb1fTy6XFiXDKep/Z5lIYSGjUkdXgq17G9hQWcfmPfVBQDTR2vnGX8DTygqZPbGIS06dyqzxRcyaUMSsCcXMHF9Ecb7+0w8jFjOK8nIoyssB8od0rO6EB8HRczmvi4bWThrbO2lo7Vnuor4lua2+tZPapg521DbT0JpcP9blv5hxOFiOfpQV9V7PO7ytrCiXssI8CnJjCpp+6P8YGRUqD7bwwq5DvLirjg2VdWzZ00BHdwKACcV5LJxawpUrZ7BgcgkLppQwb3IJYxQII1I8Zod/sI+HezJs6luT4VIfBEhPkPT12H2olbpgufsYSZMXj1FalEvZEcGSF4RJsK0o7/ByWWHe4bOZTO8woP+bZEQ60NTOU9sPsLailrXba6k82ApAYW6cU6eVct25s1k+o4zlM8qYWlqgvwaziJkFbR+5MC7ce92d5o5u6lo63giTlk7qWjupa+kJlw4ONSeX99S1sXVvI3UtHcdst4kZwVlK72B548xlXLD98D6FyW0lBaMnZBQWMiJ0J5znXz/EY1uq+eO2Wl6ubgSgJD+HM+dO4IZz57ByzngWTC4hJ67GTzk+ZpZseM/PYXrIoOnoSlDX2kFDECx1h0Om43DQHApCqLapg4r9TdQ1Jy+p9V9PMmTGHRUshy+P9Q6gXmc0Ywtyhz1kFBYSmY6uBE9tr+XRzdU8tmUftU0d5MVjrJg9js9ftIBzTprAqdNKFQ4yIuTlxJhUUsCkkoJQ7+vqTlDf2vvsJXnmUtfaSX1LB4d6hc6Bpg4qapqob0225/SnJ2TKCpOXxT761jlcvuzEoX7FY1JYyLDqTjh/qqjlly9U8butNTS2d1GcF+eChZO4aPEUzl9wQvLygkiGyInHmDAmnwljwnUM6OpO0NDWxaHgzKXn0tmhlmTI9ITPoZYOcuPpP8tQWMiw2HWghZ8/X8nPn69iT30bZUW5XHrqVC5aMplzTppIQW486hJFRpSceIzxxXmML86LuhRAYSFp1NbZzZryah5cX8lT2w9gBufNO4EvXbaIt58yifwcBYTIaKGwkJSrb+3kJ8++zj1rX2N/YzszxxfxuXfO572nT+fEssKoyxOR46CwkJSprm/j7rU7ue/ZXTS1d3He/BP49gfncs5JE0ZN90AR6ZvCQoZsx/4mvvf77Ty0YTcJh8uWTuXG8+ay+MTSqEsTkRRRWMhxO9DUzp1PbOMnz+4iJ278xcqZfPRtc5kxvijq0kQkxRQWElpbZzf3rH2N7z5ZQUtnN1etnMEtq+YzMWTXQBEZPRQWMmiJhPMfm/bw9TWvsLuulVWnTOKLlyzk5EklUZcmImmmsJBB2bavkb/9xSZe3FXH4hPH8k/vX8o5J0+MuiwRGSYKCzmmru4Ed/1xJ99+7FWK8+N84wPLeO9p09S7SSTLKCykXxU1jXz2Z5vYWFnHJUum8PfvXqJ2CZEspbCQN+lOOHf9cQffeuxVivPi3HnVaVy+dKqGARfJYgoLOcLuulZuvu8FXtxVx0WLJ/N/330qJ5TobEIk2yks5LCntx/g5vteoKMrwR1XLuddy07U2YSIABDZRAFm9lUz221mG4LHpb1eu9XMKszsFTO7KKoas4W7c8/anXz4B89SVpTLQzefyxXLpykoROSwqM8svu3u3+i9wcwWAVcCi4ETgcfNbL679z+noRy3ts5ubvtVOb94oYpVp0zm2x9apvkkRORNog6LvlwBPODu7cBOM6sAVgJPR1tW5tlT18on/v15NlXVc8uqeXz6wnnqEisifYp6vsqbzWyTmd1tZj0z4k4DKnvtUxVskxTaWFnH5d/5Ezv2N3PXX67gllXzFRQi0q+0hoWZPW5m5X08rgC+B5wELAf2At/seVsfh/J+jn+jma03s/X79+9Py3fIRM+9dpCr/+1ZivLjPHTTubxj0eSoSxKRES6tl6HcfdVg9jOzu4D/DFargBm9Xp4O7Onn+KuB1QArVqzoM1DkSGsravnoj9YztayA+z56FlNKw00+LyLZKcreUFN7rb4HKA+WHwauNLN8M5sDzAPWDXd9mejJl2u4/ofPMWtCET+98WwFhYgMWpQN3F83s+UkLzG9BnwcwN03m9mDwBagC7hJPaGGbk15NZ+6/wUWTCnh3hvOZNwImQReREaHyMLC3a85xmu3A7cPYzkZ7dcbdvM3D25k2fRS7rl+JaWF6horIuGMxK6zkkIPvbibv35wA2fOGc8Prj2D4nz9KxeR8PTLkcGe3n6Az/98I2fNmcDd151BYV486pJEZJSK+j4LSZOKmkY+fu96Zk8o5l+veYuCQkSGRGGRgWqb2rn+h8+RlxPn7uvOUBuFiAyZwiLDtHV289EfrWd/Yzs/uHYFM8YXRV2SiGSAQYWFmcXM7IPpLkaGJpFw/vqnG9hYVccdV57GshllUZckIhliUGHh7gng5jTXIkP0tTUv80h5NbddegoXLZ4SdTkikkHCXIZ6zMw+Z2YzzGx8zyNtlUko9z27i9V/2MFfnj2Lj7x1TtTliEiGCdN19obg+aZe2xyYm7py5Hhs2dPAVx/ezPkLTuDLly3SpEUiknKDDgt315+rI1BbZzefeeBFSoty+eYHlpETV58FEUm9QYeFmeUCnwTOCzb9Hvi+u3emoS4ZpNv/ayvbapq49yMrmTAmP+pyRCRDhbkM9T0gF/husH5NsO2jqS5KBufxLfu495nX+djb5vC2eSdEXY6IZLAwYXGGuy/rtf47M9uY6oJkcGoa2vjbX2xi0dSxfO6iBVGXIyIZLswF7m4zO6lnxczmAho6PAKJhPPZn22kpaOLO686jfwcDeUhIukV5szi88CTZraD5NSns4Dr01KVHNPda3fyx2213P6eJZw8aUzU5YhIFhhUWJhZDGglOWvdApJh8bK7t6exNulD+e56/nHNy7xz0WT+YuXMqMsRkSwxqLBw94SZfdPdzwY2pbkm6UdHV4JbfrqB8cV5/OP7lup+ChEZNmHaLH5rZu8z/UJF5u61O6moaeJr712qaVFFZFiFabP4G6AY6DKzNpKXotzdx6alMjlCdX0b33liG6tOmcwFCydFXY6IZJnBtlkYsNjdd6W5HunHPzyylc6E8+XLFkVdiohkocGOOuvAr9Jci/Rj3c6D/HrDHj5+3lxmTtD8FCIy/MK0WTxjZmekrRLpU1d3gi//upxpZYX81fknR12OiGSpMG0WFwCfMLPXgGbeaLNYmo7CJOm+dbt4ubqR7159uubRFpHIhAmLS9JWhfTpQFM733j0Fc49eQKXLNFkRiISnUFfhnL314EZwIXBckuY90t43/jtK7R0dPPVyxfrngoRidSgf+zN7CvAF4Bbg025wL+noyiBTVV1PPBcJdedM5t5k0uiLkdEslyYM4P3AO8i2V6Bu+8B9CuWBomE85WHNzOhOJ/PrJoXdTkiIqHCoiPoQusAZlacnpLkt1uqeXFXHV+4eAElBblRlyMiEiosHjSz7wNlZvYx4HHgrvSUlb3cne/8roI5E4t57+nToy5HRAQINwf3N8zsHUADyZFnv+zuj6Wtsiz15Cs1bN7TwD+9fynxmBq1RWRkCNN1liAc+gwIM3s6GJVWjpO7c+cTFUwfV8i7T5sWdTkiIoelsutrQQqPlZXWVhxgQ2Udnzz/JHLj6pUsIiNHKn+RPIXHykp3/m4bU8YW8P63qK1CREYW/fk6Qjy74wDrdh7k4382V3Nqi8iIk8qwUGvsEPzzkxVMHJPHlWdoqlQRGXlSGRbXpPBYWeXFXYf447ZaPva2uRosUERGpAHDwswazayhv0fPfu5eHvbDzexTZvaKmW02s6/32n6rmVUEr10U9rijzT//roKyolyuPmtW1KWIiPRpwK6z7l4CYGZ/B1QD95K85HQ1Qxjuw8wuAK4Alrp7u5lNCrYvAq4EFgMnAo+b2Xx37z7ezxrJynfX88TLNXz2HfMZkx+qJ7OIyLAJcxnqInf/rrs3unuDu38PeN8QPvuTwNfcvR3A3WuC7VcAD7h7u7vvBCqAlUP4nBHtX56soCQ/h788Z3bUpYiI9CtMWHSb2dVmFjezmJldDQzlr/35wNvM7Fkz++9es/BNAyp77VcVbMs42/Y18kh5NdedO5vSQo0BJSIjV5jrHn8B3BE8HFgbbOuXmT0O9DVrz23BZ48DzgLOIDn21Fz67lXV5z0cZnYjcCPAzJmjrxfRj59+nbycGNefOyfqUkREjinM2FCvkbxENGjuvqq/18zsk8Avg5Fs15lZAphI8kxiRq9dpwN7+jn+amA1wIoVK0bVTYEtHV089OJuLjt1KuOL86IuR0TkmMJMfjTfzJ4ws/JgfamZfWkIn/0QcGHPsYE8oBZ4GLjSzPLNbA4wD1g3hM8Zkf5z014a27u46szRd0YkItknTJvFXSRnyesEcPdNJHstHa+7gblB+DwAXOtJm4EHgS3AGuCmTOwJdf+6XZw8aQwrZo2LuhQRkQGFabMocvd1R80F3XW8H+zuHcCH+3ntduD24z32SLd1bwMv7qrjS39+iubWFpFRIcyZRa2ZncQbM+W9H9iblqoy3APrdpEXj/E+TW4kIqNEmDOLm0g2Ji80s93ATpI35kkIrR3d/PLF3Vxy6hTGqWFbREaJQYWFmcWAFe6+Kph7O+bujektLTP910t7aWzr4qqVatgWkdFjUJeh3D0B3BwsNysojt/963Yxd2IxZ84ZH3UpIiKDFqbN4jEz+5yZzTCz8T2PtFWWgV6pbuT51w9x1cqZatgWkVElTJvFDcHzTb22OTA3deVktvt7GrY1E56IjDJh7uDWmBRD0NbZzS9fqOKiJVN0x7aIjDqhxsQ2syXAIqCgZ5u7/zjVRWWi37y0l4a2Lq5aOWPgnUVERphBh4WZfQU4n2RY/Aa4BPgToLAYhAfWVTJ7QhFnz50QdSkiIqGFaeB+P/B2oNrdrweWAflpqSrDVNQ0su61g2rYFpFRK0xYtAZdaLvMbCxQgxq3B+Wnz1WSGzc1bIvIqBWmzWK9mZWRHFDweaCJDBwNNtXcnd+8VM3b5p3AxDE6EROR0SlMb6i/Chb/1czWAGODkWflGF7aXc/uulY+s2pe1KWIiBy3MA3c5/W1zd3/kNqSMsua8mriMeMdp0yOuhQRkeMW5jLU53stFwArSV6OujClFWUQd2dNeTVnz52gQQNFZFQLcxnq8t7rZjYD+HrKK8ogr+5rYkdtMze8VfczisjoFqY31NGqgCWpKiQTPVK+FzN452JdghKR0S1Mm8V3CCY+Ihkyy4GN6SgqU6wpr+aMWeOZVFIw8M4iIiNYqK6zvZa7gPvdfW2K68kYO2ubebm6kf992aKoSxERGbIwbRY/SmchmeaR8uSMsxcvmRJxJSIiQxfmMtRLvHEZ6oiXAHf3pSmrKgOsKa9m2fRSppUVRl2KiMiQhbkM9UjwfG/wfDXQAuiM4yhVh1rYVFXPFy5eGHUpIiIpESYsznX3c3utf9HM1rr736W6qNFuTXk1AJfoEpSIZIgwXWeLzeytPStmdg5QnPqSRr9HN1ezcEoJsyfqH4+IZIYwZxYfAe42s9JgvY43plqVQE1jG+tfP8Qtb58fdSkiIikTpjfU88CyYHhyc/f69JU1ej26eR/u6gUlIpll0JehzOwzQVA0At80sxfM7J3pK210WlO+l7kTi5k/eUzUpYiIpEyYNosb3L0BeCcwCbge+FpaqhqlDjV38MyOg1y8ZIpmxBORjBImLHp+/S4F7nH3jb22CfDYln10J5xLlkyNuhQRkZQKExbPm9lvSYbFo2ZWAiTSU9botGZzNdPHFbJk2tioSxERSakwYfER4IvAGe7eAuSRvBQFgJktTnFto0pHV4Kntx/gwoWTdAlKRDJOmN5QCeCFXusHgAO9drkXOD11pY0uGyrraO3s5pyTJkZdiohIyg1lPoujZfWf02sraokZnD13QtSliIikXCrDoq9BBrPGU9trWTKtlNKi3KhLERFJuVSGRdZqbu/ixV11ugQlIhkrlWHRkcJjjSrrXjtIV8I592RdghKRzBRmbCjMbBowq/f73P0PwfNZIY/1U2BBsFoG1Ln78uC1W0n2vuoGPu3uj4Y59nB7qqKWvHiMFbPGR12KiEhahJn86B+BDwFbSP6IQ7Kd4g/H88Hu/qFex/4mUB8sLwKuBBYDJwKPm9l8d+/u80AjwNqKA5w+q4zCvHjUpYiIpEWYM4t3AwvcvT2VBVjypoQPAhcGm64AHgg+Z6eZVQArgadT+bmpcrC5gy17G/jsOzTKrIhkrjBtFjuAdHT1eRuwz923BevTgMper1cF297EzG40s/Vmtn7//v1pKG1gT29P3mpyzslq3BaRzBXmzKIF2GBmTwCHzy7c/dP9vcHMHgf6Gqv7Nnf/dbB8FXB/77f1sX+f3XLdfTWwGmDFihWRdN1du72WMfk5LJteOvDOIiKjVJiweDh4DJq7rzrW62aWA7wXeEuvzVXAjF7r04E9YT53OD29/QAr54wnJ65eyCKSucIM9/GjNHz+KuBld6/qte1h4D4z+xbJBu55wLo0fPaQ7alrZWdtM1efOTPqUkRE0ipMb6h5wD8Ai4CCnu3uPncIn38lR16Cwt03m9mDJHtddQE3jdSeUGsragE4V+0VIpLhwlyGugf4CvBt4AKSI84OaTwod7+un+23A7cP5djD4antB5hQnMeCySVRlyIiklZhLrQXuvsTJOffft3dv8ob3V2zjruztqKWs0+aQCyW1WMoikgWCHNm0WZmMWCbmd0M7CY5vWpW2r6/iZrGdl2CEpGsEObM4hagCPg0yd5LHwauTUdRo8HaiuT9Fedq8EARyQJhekM9B2Bm7u7XD7R/pltbUcv0cYXMnFAUdSkiImk36DMLMzvbzLYAW4P1ZWb23bRVNoJ1J5xndhzQWYWIZI0wl6H+P3ARwVSq7r4ROC8dRY105bvraWjr4hwNSS4iWSLUbcfuXnnUphF5/0O6PRWMB3X2SQoLEckOYXpDVZrZOYCbWR7Jhu6t6SlrZHtqey3zJ49hUknBwDuLiGSAMGcWnwBuIjkCbBWwPFjPKp3dCZ577aCmUBWRrBKmN1QtcHUaaxkVXqlupK0zwYrZ46IuRURk2IQZG2oO8ClgNkdOq/qu1Jc1cm2orANg2fSyiCsRERk+YdosHgJ+APwHkEhPOSPfpqo6xhfnMX1cYdSliIgMm1DDfbj7nWmrZJTYWFnP0umlJGeDFRHJDmHC4g4z+wrwW46cKe+FlFc1QjW3d7GtppGLl/Q1+Z+ISOYKExanAteQHGm25zKUk0Ujz5bvrifhsGyGplAVkewSJizeA8x19450FTPSbaxKNm4vVeO2iGSZMPdZbASy+ldyY1U908oKmTgmP+pSRESGVZgzi8nAy2b2HEe2WWRN19mNlXUsn5HVeSkiWSpMWHwlbVWMAgea2qk61Mo1Z82KuhQRkWEX5g7u/z7W62b2tLufPfSSRqZNVfUALNOZhYhkoVCjzg4go0fV21hVhxksmaaeUCKSfVIZFp7CY404GyvrmDdpDGPyw1y5ExHJDKkMi4zl7myqqleXWRHJWqkMi4wd/6LqUCsHmjvUXiEiWSuVYXFNCo81ohxu3J6u9goRyU5hhihv5M3tEvXAeuCz7l6eysJGko1VdeTFYyycMjbqUkREIhGmtfZbwB7gPpKXnK4EpgCvAHcD56e6uJFiY2Udp5w4lrwcNfGISHYK8+t3sbt/390b3b3B3VcDl7r7T4GMnTauO+G8tLue5boEJSJZLExYJMzsg2YWCx4f7PVaxnab3b6/iZaObvWEEpGsFiYsribZiF0D7AuWP2xmhcDNaahtRDg8jap6QolIFgsz3McO4PJ+Xv5TasoZeTZV1VGSn8PcicVRlyIiEplBn1mY2Xwze8LMyoP1pWb2pfSVNjJsrKzn1OmlxGIZexuJiMiAwlyGugu4FegEcPdNJHtEZay2zm5erm5Qe4WIZL0wYVHk7uuO2taVymJGmq17G+jsdpZrGlURyXJhwqLWzE4i6PlkZu8H9qalqhGi585tnVmISLYLExY3Ad8HFprZbuAW4BPH+8FmttzMnjGzDWa23sxWBtvNzO40swoz22Rmpx/vZwzVxso6TijJZ2ppRo++LiIyoDB3cO8G7gGeBMYDDcC1wN8d52d/Hfg/7v6ImV0arJ8PXALMCx5nAt8Lnofdxqo6lk0vxUyN2yKS3cKcWfyaZNfZTpLDfjQBzUP4bAd6BlsqDY4JcAXwY096Bigzs6lD+Jzj0tDWyfb9zSzTJSgRkVBnFtPd/eIUfvYtwKNm9g2SoXVOsH0aUNlrv6pg27C2j2zZ0wDAqRrmQ0QkVFg8ZWanuvtLg32DmT1OcrDBo90GvB34a3f/RTB0yA+AVfQ9L0afw4mY2Y3AjQAzZ84cbFmDsm1fIwALppSk9LgiIqNRmLB4K3Cdme0E2kn+qLu7L+3vDe6+qr/XzOzHwGeC1Z8B/xYsVwEzeu06nTcuUR19/NXAaoAVK1akdHyqbTVNlOTnMGWsGrdFRMKExSUp/uw9wJ8BvwcuBLYF2x8GbjazB0g2bNe7+7B30X11XyMnTx6jxm0REcKNDfV6ij/7Y8AdZpYDtBFcTgJ+A1wKVAAtwPUp/txBqahp4sKFk6L4aBGRESfMmUVKufufgLf0sd1J3tMRmYPNHdQ2dTBvktorREQgtXNwZ4yexu15k8dEXImIyMigsOjDtpomAOZN1pmFiAgoLPpUUdNEcV6cEzXMh4gIoLDoU7InVIl6QomIBBQWfdhW08S8SWqvEBHpobA4Sl1LB/sb25mvxm0RkcMUFkc53LitbrMiIocpLI6ybV8yLE7WZSgRkcMUFkd5dV8jRXlxppUVRl2KiMiIobA4SkVNEydPGkMspp5QIiI9FBZH2VbTqEtQIiJHUVj0Ut/ayb6Gdubrzm0RkSMoLHqpqAnGhNKZhYjIERQWvfT0hNKZhYjIkRQWvby6r4mC3Jh6QomIHEVh0UtP47Z6QomIHElh0UtFTRPzdee2iMibKCwCDW2d7K1v42SNCSUi8iYKi0CFxoQSEemXwiJQcbgnlM4sRESOprAIvLqvkfycGNPHFUVdiojIiKOwCGyraeKkE8YQV08oEZE3UVgEtu1r1CUoEZF+KCyAxrZO9tS3MU93bouI9ElhAWzf3wxoTCgRkf4oLEg2bgM6sxAR6YfCguQ9Fnk5MWaOV08oEZG+KCxINm6rJ5SISP8UFiRHm1V7hYhI/7I+LJrbu9hd16qwEBE5hqwPi+37gzGh1LgtItKvrA+LV/f1hIXOLERE+pP1YTGhOI9Vp0xilnpCiYj0KyfqAqJ2wcJJXLBwUtRliIiMaFl/ZiEiIgNTWIiIyIAiCwszW2ZmT5vZS2b2H2Y2ttdrt5pZhZm9YmYXRVWjiIgkRXlm8W/AF939VOBXwOcBzGwRcCWwGLgY+K6ZxSOrUkREIg2LBcAfguXHgPcFy1cAD7h7u7vvBCqAlRHUJyIigSjDohx4V7D8AWBGsDwNqOy1X1WwTUREIpLWrrNm9jgwpY+XbgNuAO40sy8DDwMdPW/rY3/v5/g3AjcCzJw5c8j1iohI39IaFu6+aoBd3glgZvOBPw+2VfHGWQbAdGBPP8dfDawGWLFiRZ+BIiIiQ2fu0fzGmtkkd68xsxjwQ+D37n63mS0G7iPZTnEi8AQwz927BzjefuD1NJedDhOB2qiLGGb6zpkv274vjN7vPMvdTxhopyjv4L7KzG7j5ruEAAAEF0lEQVQKln8J3APg7pvN7EFgC9AF3DRQUATvG/DLjkRmtt7dV0Rdx3DSd8582fZ9IfO/c2Rh4e53AHf089rtwO3DW5GIiPRHd3CLiMiAFBbRWx11ARHQd8582fZ9IcO/c2QN3CIiMnrozEJERAaksIiYmf2Tmb1sZpvM7FdmVhZ1TelmZh8ws81mljCzjO09AmBmFwcDYlaY2RejrifdzOxuM6sxs/KoaxkuZjbDzJ40s63Bf9efibqmdFBYRO8xYIm7LwVeBW6NuJ7hUA68lzfGBstIwQCY/wJcAiwi2V18UbRVpd0PSQ4Amk26gM+6+ynAWcBNmfjvWWERMXf/rbt3BavPkLxjPaO5+1Z3fyXqOobBSqDC3Xe4ewfwAMmBMjOWu/8BOBh1HcPJ3fe6+wvBciOwlQwcz05hMbLcADwSdRGSMhoUM8uY2WzgNODZaCtJvayfg3s4HGtARXf/dbDPbSRPZ38ynLWly2C+cxYY9KCYMvqZ2RjgF8At7t4QdT2pprAYBgMNqGhm1wKXAW/3DOnLPIhBJLPBoAfFlNHNzHJJBsVP3P2XUdeTDroMFTEzuxj4AvAud2+Juh5JqeeAeWY2x8zySM4A+XDENUmKmZkBPwC2uvu3oq4nXRQW0ftnoAR4zMw2mNm/Rl1QupnZe8ysCjgb+C8zezTqmtIh6LhwM/AoyUbPB919c7RVpZeZ3Q88DSwwsyoz+0jUNQ2Dc4FrgAuD/4c3mNmlUReVarqDW0REBqQzCxERGZDCQkREBqSwEBGRASksRERkQAoLEREZkMJCZAjM7DUzmzjUfURGOoWFiIgMSGEhMkhm9pCZPR/MWXDjUa/NDuYl+VEwN8nPzayo1y6fMrMXzOwlM1sYvGelmT1lZi8GzwuC7YvNbF1wc9cmM5s3jF9TpE8KC5HBu8Hd3wKsAD5tZhOOen0BsDqYm6QB+Kter9W6++nA94DPBdteBs5z99OALwP/L9j+CeAOd18efFZVWr6NSAgKC5HB+7SZbSQ578gM4Oi/+CvdfW2w/O/AW3u91jO43PPA7GC5FPhZMKvct4HFwfangf9lZl8AZrl7a0q/hchxUFiIDIKZnQ+sAs5292XAi0DBUbsdPXZO7/X24LmbN0Z7/nvgSXdfAlzeczx3vw94F9AKPGpmF6boa4gcN4WFyOCUAofcvSVoczirj31mmtnZwfJVwJ8GcczdwfJ1PRvNbC6ww93vJDlK7dKhFC6SCgoLkcFZA+SY2SaSZwTP9LHPVuDaYJ/xJNsnjuXrwD+Y2Vog3mv7h4ByM9sALAR+PNTiRYZKo86KpEAwneZ/BpeURDKOzixERGRAOrMQEZEB6cxCREQGpLAQEZEBKSxERGRACgsRERmQwkJERAaksBARkQH9DwDgfFTRwtf4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108585090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=0.15306122448979576, copy_X=True, fit_intercept=True,\n",
      "   max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "   tol=0.001)\n"
     ]
    }
   ],
   "source": [
    "# Use grid search to determine the optimal regularization parameters for our model\n",
    "from sklearn import grid_search\n",
    "\n",
    "alphas = np.linspace(-2.5,2.5,50)\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=linear_model.Ridge(),\n",
    "    param_grid={'alpha': alphas},\n",
    "    scoring='neg_mean_squared_error')\n",
    "\n",
    "gs.fit(modeldata, y)\n",
    "\n",
    "print(gs.param_grid) # Parameter space explored\n",
    "print(gs.best_score_) # Best 'neg_mean_squared_error'\n",
    "plt.plot(alphas,[s[1] for s in gs.grid_scores_],)\n",
    "plt.xlabel('alphas')\n",
    "plt.ylabel('neg_mean_squared_error')\n",
    "plt.show()\n",
    "print(gs.best_estimator_) # Best combination of paramaters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: When does regularization come into play? \n",
    "\n",
    "**Regularization**: is a process of introducing additional information in order to prevent overfitting\n",
    "- a technique to improve the generalizability of a learned model\n",
    "- imposes a penalty on the complexity of model predictions\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Regularization.svg/249px-Regularization.svg.png)\n",
    "\n",
    "We saw how to use regularization first in Lesson 07- we used cross-validation to optimize the regularization of our linear regression model.   \n",
    "Regularization refers to a variety of techniques, but with linear regression in particular, either Lasso (L1) and Ridge (L2) regularization are available.\n",
    "- _Rule-of-thumb_: use Lasso (L1) when we have a higher number of features (k) than we have observations (n), and use Ridge (L2) in about all other cases  \n",
    "We have also seen that we can use regularization with logistic regression, by setting 'C'- the inverse of regularization (smaller values specify stronger regularization). Regularization is also useful for SVM models, among others.  \n",
    "Regularizers typically have their own parameters, which need to optimized. In the previous cell, we found the ideal value for Ridge parameter _alpha_.  \n",
    "![](http://scikit-learn.org/stable/_images/sphx_glr_plot_ridge_path_001.png)\n",
    "The point here is that as the regularization grows greater (right to left), the coefficients are drawn towards zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 0\n",
      "('Linear model coeff:', array([ 0.7284403 ,  2.30926001, -0.08219169]))\n",
      "('Ridge model coeff:', array([0.93832131, 1.05887277, 0.87652644]))\n",
      "Random seed 1\n",
      "('Linear model coeff:', array([ 1.15181561,  2.36579916, -0.59900864]))\n",
      "('Ridge model coeff:', array([0.98409577, 1.06792673, 0.75855367]))\n",
      "Random seed 2\n",
      "('Linear model coeff:', array([0.69734749, 0.32155864, 2.08590886]))\n",
      "('Ridge model coeff:', array([0.97159124, 0.94256202, 1.08539406]))\n",
      "Random seed 3\n",
      "('Linear model coeff:', array([0.28735446, 1.25386129, 1.49054726]))\n",
      "('Ridge model coeff:', array([0.91891806, 1.00474386, 1.03276594]))\n",
      "Random seed 4\n",
      "('Linear model coeff:', array([0.18726691, 0.77214206, 2.1894915 ]))\n",
      "('Ridge model coeff:', array([0.96401621, 0.98152524, 1.0983599 ]))\n",
      "Random seed 5\n",
      "('Linear model coeff:', array([-1.2912413 ,  1.59097473,  2.74727029]))\n",
      "('Ridge model coeff:', array([0.75819864, 1.01085804, 1.1390417 ]))\n",
      "Random seed 6\n",
      "('Linear model coeff:', array([ 1.19909595, -0.0306915 ,  1.91454912]))\n",
      "('Ridge model coeff:', array([1.01616507, 0.89032238, 1.0907386 ]))\n",
      "Random seed 7\n",
      "('Linear model coeff:', array([ 1.47386769,  1.76236014, -0.15057274]))\n",
      "('Ridge model coeff:', array([1.0179376 , 1.03865514, 0.90082373]))\n",
      "Random seed 8\n",
      "('Linear model coeff:', array([0.0840547 , 1.87985845, 1.10688887]))\n",
      "('Ridge model coeff:', array([0.90685834, 1.07119752, 1.00837994]))\n",
      "Random seed 9\n",
      "('Linear model coeff:', array([0.71408648, 0.77601368, 1.36406398]))\n",
      "('Ridge model coeff:', array([0.89617178, 0.90340866, 0.98015958]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "size = 100\n",
    " \n",
    "# We run the method 10 times with different random seeds\n",
    "for i in range(10):\n",
    "    print(\"Random seed %s\" % i)\n",
    "    np.random.seed(seed=i)\n",
    "    X_seed = np.random.normal(0, 1, size)\n",
    "    X1 = X_seed + np.random.normal(0, .1, size)\n",
    "    X2 = X_seed + np.random.normal(0, .1, size)\n",
    "    X3 = X_seed + np.random.normal(0, .1, size)\n",
    "    Y = X1 + X2 + X3 + np.random.normal(0, 1, size)\n",
    "    X = np.array([X1, X2, X3]).T\n",
    " \n",
    "    lr = LinearRegression().fit(X,Y)\n",
    "    print(\"Linear model coeff:\", lr.coef_)\n",
    " \n",
    "    ridge = Ridge(alpha=10).fit(X,Y)\n",
    "    print(\"Ridge model coeff:\", ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point here is that the coefficients can vary widely for linear regression, depending on the generated data. For L2 regularized model however, the coefficients are quite stable and closely reflect how the data was generated (all coefficients close to 1)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
