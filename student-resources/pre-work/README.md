# DS-SF-44 Pre-work Summary

#### Note: Make sure you have completed *ALL* of the [assigned pre-work](../ds-prework-student.md) before completing the following exercises for each session

Class | Pre-work (be able to...)
--- | ---
3/20: Intro to Data Science | - Define [basic data types used in object-oriented programming](https://www.computerhope.com/jargon/d/datatype.htm) <br /> - Recall the Python syntax for [lists, dictionaries, and functions](http://thomas-cokelaer.info/tutorials/python/data_structures.html) <br /> - Create files and navigate directories using the [command line interface](https://www.codecademy.com/courses/learn-the-command-line/lessons/navigation/exercises/your-first-command)
3/22: Numpy & Pandas | - Can [create and open an Jupyter Notebook](https://unidata.github.io/online-python-training/notebook.html)
3/27: Statistics Fundamentals I | No pre-reqs
3/29: Statistics Fundamentals II | - Explain the [difference between variance and bias](http://scott.fortmann-roe.com/docs/BiasVariance.html) <br /> - Use [descriptive statistics](https://machinelearningmastery.com/understand-machine-learning-data-descriptive-statistics-python/) to understand your data
4/3: Data Science Toolkit | No pre-reqs
4/5: Introduction to Linear Regression | - Effectively [show correlations between an independent variable x and a dependent variable y](http://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Correlation-Regression/BS704_Correlation-Regression_print.html) <br /> - Be familiar with the [get_dummies function in pandas](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) <br /> -Understand the [difference between vectors, matrices, Series, and DataFrames](https://pandas.pydata.org/pandas-docs/stable/dsintro.html) <br /> - Understand the concepts of [outliers and distance](https://machinelearningmastery.com/how-to-identify-outliers-in-your-data/) <br /> - Be able to interpret [p values and confidence intervals](http://blog.minitab.com/blog/adventures-in-statistics-2/understanding-hypothesis-tests%3A-confidence-intervals-and-confidence-levels)
4/10: Evaluating Model Fit | - Understand goodness of [fit (r-squared)](http://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit) <br /> - [Measure statistical significance](http://blog.minitab.com/blog/adventures-in-statistics-2/how-to-interpret-regression-analysis-results-p-values-and-coefficients) of features <br /> - Recall what a [residual](http://stattrek.com/regression/residual-analysis.aspx?Tutorial=AP) is <br /> - Implement a [sklearn estimator](http://scikit-learn.org/stable/tutorial/statistical_inference/settings.html) to predict a target variable
4/12: Intro to classification | - Understand how to [optimize for error in a model](https://machinelearningmastery.com/implement-logistic-regression-stochastic-gradient-descent-scratch-python/) <br /> - Understand the concept of [iteration to solve problems](https://www.pythonlearn.com/html-008/cfbook006.html) <br /> - Measure [basic probability](https://towardsdatascience.com/basic-probability-theory-and-statistics-3105ab637213)
4/17: Intro to Logistic Regression | - Implement a [linear model (LinearRegression) with sklearn or statsmodels](http://bigdata-madesimple.com/how-to-run-linear-regression-in-python-scikit-learn/) <br /> - Define the concept of [coefficients](http://statisticsbyjim.com/glossary/regression-coefficient/) <br /> - Recall metrics for [accuracy and misclassification](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/) <br /> - Recall the differences between [L1 and L2 regularization](https://www.r-bloggers.com/machine-learning-explained-regularization/)
4/19: Communicating the Results of Logistic Regression | - Understand results from a [confusion matrix, and measure true positive rate and false positive rate](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/) <br /> - Create and interpret results from a [binary classification problem](http://blog.yhat.com/posts/logistic-regression-and-python.html) <br /> - Know what a [decision line is in logistic regression](http://www.holehouse.org/mlclass/06_Logistic_Regression.html)
4/24: Clustering | - Use [sckit-learn](http://scikit-learn.org/stable/tutorial/basic/tutorial.html) to fit models <br /> - Use [seaborn](https://www.datacamp.com/community/tutorials/seaborn-python-tutorial) to create plots <br /> - Understand the similarities/differences between [_supervised_ and _unsupervised_ learning models](https://medium.com/@machadogj/ml-basics-supervised-unsupervised-and-reinforcement-learning-b18108487c5a)
4/26: Decision Trees | - Familiarity with [bootstrap sampling](https://machinelearningmastery.com/calculate-bootstrap-confidence-intervals-machine-learning-results-python/) <br /> - Explain the concepts of [cross-validation, overfitting](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6), and [logistic regression](http://blog.yhat.com/posts/logistic-regression-and-python.html) <br /> - Know how to build and evaluate some classification model in [scikit-learn using cross-validation and AUC](http://www.ritchieng.com/machine-learning-evaluate-classification-model/)
5/1: NLP with Classification | - Experience with sckit-learn classifiers, specifically [Random Forests and Decision Trees](https://jakevdp.github.io/PythonDataScienceHandbook/05.08-random-forests.html) <br /> - [Install spacy](https://spacy.io/usage/#conda) with conda install spacy (or use [pip](https://spacy.io/usage/#pip) <br /> - Run the spacy [download data command](https://spacy.io/usage/#installation): ```python -m spacy download en```
5/3: Latent Variable Models | - Install gensim with pip install gensim <br /> - Recall and apply unsupervised learning techniques <br /> - Recall probability distributions, specifically discrete multinomial distributions <br /> - Recall NLP essentials, including experience with spacy <br /> - BONUS: If you are interested in accessing the Twitter API, you'll need to [setup Twitter API credentials](./twitter-instructions.md)
5/8: Time-series Data | - Load data with Pandas, plotting data with Seaborn <br /> - Define and explain the concept of correlation
5/10: Modeling Time-series Data | - Prior definition and Python functions for moving averages and autocorrelation <br /> - Prior exposure to linear regression with discussion of coefficients and residuals <br /> - pip install statsmodels (should be included with Anaconda)
5/15: Databases | There will be multiple ways to run the exercises: <br /> - Using Postgres Exercises <br /> - Setting up local Postgres <br /> - Install Postgres: if brew is installed, this should be as simple as brew install postgres <br /> - Using Wagon: Create an account at https://www.wagonhq.com/ and download the software
5/17: Next Steps with Data Science | - Define the data science workflow <br /> - Apply course information to your own professional interests
5/22: Neural Networks | - Understand Logistic Regression and link functions <br /> - Be familiar with training and testing classifiers and regressors
5/24: Final Presentations!!! |
