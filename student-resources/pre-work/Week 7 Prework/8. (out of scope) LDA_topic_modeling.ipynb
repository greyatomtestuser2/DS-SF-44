{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[logo placeholder]\n",
    "\n",
    "## Flex Talk:  Topic Modeling\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2 Mins) - What do you know about topic modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrasting Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Engines\n",
    "\n",
    "Search Engines use a variety of natural language processing techniques in order to provide an accurate query interface to documents on the internet.  LDA is just one of the tools that is employed to help use this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](https://snag.gy/lbsuV2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://snag.gy/YdgxKz.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://snag.gy/Ctr6OL.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://snag.gy/ob9Um8.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Topics generated from an LDA model are actually a cluster of word probabilities, not clearly defined labels.  Simplifying word vectors like this, should give you a sense about the intuition of how **words vectors** relate to **topics**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How LDA Works\n",
    "_Abridged Explanation_\n",
    "\n",
    "![](https://snag.gy/aiSFrm.jpg)\n",
    "\n",
    "LDA isn't exactly as straight forward as it sounds when it comes to the actual math.  We will attempt to explore this in more general terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, choose K topics\n",
    "\n",
    "Kind of like KNN but we are deciding, up front, on a preset number of topics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Word / Topic Probabilities\n",
    "\n",
    "![](https://snag.gy/yx9grm.jpg)\n",
    "\n",
    "**For each possible topic Z, and each word:**\n",
    "1. Multiply the frequency of the word by the total number of words already in topic Z\n",
    "\n",
    "This gives us a probability that each word exists in the preset number of topics.\n",
    "\n",
    "> The term here that is unfamilliar is a hyperparameter, *alpha*.  In this case, alpha is a scaler that helps minimize an error term.  Thankfully, most LDA models that are implented will set this automatically and it's usually, 95% of the time, a fine solution.  To really get a strong handle of the math behind this model, there are whitepapers you can read.  Also, having a strong handle on Bayesian statistis is a must to really grasp this model at it's lowest levels.  We are not going there today!\n",
    "\n",
    "> One problem **alpha** solves is leaving the window of opportunity open when a word may only belong in a single topic, that doesn't exist in any others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Intuition\n",
    " \n",
    "Using the previous assumption about how words are assigned to topics, as we iterate through each word in our corpus, and assign to topics:\n",
    "\n",
    "1. Words become more common in topics where they are already common.\n",
    "1. Topics will become more common in documents where they are already common.\n",
    "\n",
    "**With LDA**:\n",
    "- Words are assigned to topics randomly at first\n",
    "- As words are found to be consistently distributed within topics, the model achieves a sort of balance based on the distribution of words accross all documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Challenges\n",
    "\n",
    "1. **There's a bit of entropy to topics.**\n",
    "There can be between %1-10 shift in what is generated in LDA models.  You may not get the same thing 2x!\n",
    "\n",
    "1. **Can be very difficult to assess.**\n",
    "If you have a large corpus, with many topics (>10), it's damn near impossible to visualize the distribution of documents to topics.\n",
    "\n",
    "1. **Preprocessing is heavy.**\n",
    "To get the most out of LDA, cleaning stopwords, and specific language can be a challenging task.  Sometimes it's difficult to avoid the noise involved with this model.\n",
    "\n",
    "1. **SME is necessary for accurate topic assessment.**\n",
    "The more straight forward your text is, the less subject matter expertise is required.  A more advanced use of LDA would involve assessing documents with lots of idiomtic language. Knowing what topics are found, can be subjective.\n",
    "\n",
    "1.  **Determining what topics mean, is tricky.**\n",
    "A collection of world probabiltiies generally isn't very intuitive.  You could take the first word and use that as your topic \"label\".  Hence, subject matter expertise.\n",
    "\n",
    "1. **LDA is unsupervised.**\n",
    "It's not possible to know what is \"correct\".  The repsonse topics are generated, hence this is why LDA is known as a \"generative\" model. \n",
    "\n",
    "1. **Tuning your LDA model can be tough.\"**\n",
    "With other unsupervised models, it's possible to tune for the parameter **K** *number of topics*, but it's not necessarily a very accurate method.  There are things you can do to assess the main paramter **K**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Strengths\n",
    "\n",
    "1. **It can be very strong performer in production.**\n",
    "After you build the model, it can easily be used \"online\".\n",
    "> \"Online\" training allows you to update your model with more training data without having to refit all your data.  Only new data can be fit globally.\n",
    "\n",
    "1.  **It's easy to get a quick sense of what a large body of text is broadly \"about\", without having to read all of it.** Rather than reading 12k PDF's on corproate policies, you could extract the text, and run LDA to see what generalities it finds.\n",
    "1.  **Easily classify / tag documents by topic.**\n",
    "1.  **It can \"just work\" out of the box.**  However, your mileage will vary depending on your preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Types of LDA models\n",
    "\n",
    "- Topics Over Time\n",
    "- Dynamic Topic Modeling\n",
    "- Hierarchical LDA\n",
    "- Pachinko Allocation \n",
    "\n",
    "A cool new LDA model to look out for:\n",
    "\n",
    "- LDA2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Codealong!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now explore a brief walkthrough of a small collection of documents represented by a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, matutils\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "doc_a = \"Brocolli is good to eat. My brother likes to eat good brocolli, but not my mother.\"\n",
    "doc_b = \"My mother spends a lot of time driving my brother around to baseball practice.\"\n",
    "doc_c = \"Some health experts suggest that driving may cause increased tension and blood pressure.\"\n",
    "doc_d = \"I often feel pressure to perform well at school, but my mother never seems to drive my brother to do better.\"\n",
    "doc_e = \"Health professionals say that brocolli is good for your health.\"\n",
    "\n",
    "# compile sample documents into a list\n",
    "documents = [doc_a, doc_b, doc_c, doc_d, doc_e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out the tokens that were saved, after stopword removal.\n",
    "\n",
    "Each token, has a value of it's feature offset in the internal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'baseball': 0,\n",
       " u'better': 1,\n",
       " u'blood': 2,\n",
       " u'brocolli': 3,\n",
       " u'brother': 4,\n",
       " u'cause': 5,\n",
       " u'drive': 6,\n",
       " u'driving': 7,\n",
       " u'eat': 8,\n",
       " u'experts': 9,\n",
       " u'feel': 10,\n",
       " u'good': 11,\n",
       " u'health': 12,\n",
       " u'increased': 13,\n",
       " u'likes': 14,\n",
       " u'lot': 15,\n",
       " u'mother': 16,\n",
       " u'perform': 17,\n",
       " u'practice': 18,\n",
       " u'pressure': 19,\n",
       " u'professionals': 20,\n",
       " u'say': 21,\n",
       " u'school': 22,\n",
       " u'spends': 23,\n",
       " u'suggest': 24,\n",
       " u'tension': 25,\n",
       " u'time': 26}"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts of tokens\n",
    "\n",
    "What is being counted?\n",
    "\n",
    "_Warning: big ugly sparse matrix ahead._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseball</th>\n",
       "      <th>better</th>\n",
       "      <th>blood</th>\n",
       "      <th>brocolli</th>\n",
       "      <th>brother</th>\n",
       "      <th>cause</th>\n",
       "      <th>drive</th>\n",
       "      <th>driving</th>\n",
       "      <th>eat</th>\n",
       "      <th>experts</th>\n",
       "      <th>...</th>\n",
       "      <th>perform</th>\n",
       "      <th>practice</th>\n",
       "      <th>pressure</th>\n",
       "      <th>professionals</th>\n",
       "      <th>say</th>\n",
       "      <th>school</th>\n",
       "      <th>spends</th>\n",
       "      <th>suggest</th>\n",
       "      <th>tension</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   baseball  better  blood  brocolli  brother  cause  drive  driving  eat  \\\n",
       "0         0       0      0         2        1      0      0        0    2   \n",
       "1         1       0      0         0        1      0      0        1    0   \n",
       "2         0       0      1         0        0      1      0        1    0   \n",
       "3         0       1      0         0        1      0      1        0    0   \n",
       "4         0       0      0         1        0      0      0        0    0   \n",
       "\n",
       "   experts  ...   perform  practice  pressure  professionals  say  school  \\\n",
       "0        0  ...         0         0         0              0    0       0   \n",
       "1        0  ...         0         1         0              0    0       0   \n",
       "2        1  ...         0         0         1              0    0       0   \n",
       "3        0  ...         1         0         1              0    0       1   \n",
       "4        0  ...         0         0         0              1    1       0   \n",
       "\n",
       "   spends  suggest  tension  time  \n",
       "0       0        0        0     0  \n",
       "1       1        0        0     1  \n",
       "2       0        1        1     0  \n",
       "3       0        0        0     0  \n",
       "4       0        0        0     0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup LDA Model!\n",
    "\n",
    "First we setup the vocabulary.  We could do this in 1 of 2 ways.  The quick and dirty way is to build a dictionary with a keys representing the feature offset of the tokens in the matrix, with the tokens as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: u'baseball',\n",
       " 1: u'better',\n",
       " 2: u'blood',\n",
       " 3: u'brocolli',\n",
       " 4: u'brother',\n",
       " 5: u'cause',\n",
       " 6: u'drive',\n",
       " 7: u'driving',\n",
       " 8: u'eat',\n",
       " 9: u'experts',\n",
       " 10: u'feel',\n",
       " 11: u'good',\n",
       " 12: u'health',\n",
       " 13: u'increased',\n",
       " 14: u'likes',\n",
       " 15: u'lot',\n",
       " 16: u'mother',\n",
       " 17: u'perform',\n",
       " 18: u'practice',\n",
       " 19: u'pressure',\n",
       " 20: u'professionals',\n",
       " 21: u'say',\n",
       " 22: u'school',\n",
       " 23: u'spends',\n",
       " 24: u'suggest',\n",
       " 25: u'tension',\n",
       " 26: u'time'}"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the fastest way to swap a dictionary key / value order.  This is the format gensim LDA expects it's vocabulary.\n",
    "vocab = {v: k for k, v in vectorizer.vocabulary_.iteritems()}\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default token mapping method\n",
    "Otherwise, you can use this dictionary method that is much more standard for working with gensim models for the id2word parameter of the model.  \n",
    "\n",
    "**Why would you use this instead?**\n",
    "\n",
    "The main advantage is that this dictionary method allows for quick helper functions that allow you to quickly access common points of interest like tokens, token -> id mappings.  However, there are some performance advantages if you ever want to save your model to a file, then load it at a later time.  Because the tokenizations can take a while to be computed, you can save these post computed items to file, then load them from disk later which is quite a bit faster.  Also, it's possible to add new documents to your corpus without having to re-tokenize your entire set.  This is great for online systems that can take new documents on demmand.  \n",
    "\n",
    "As you work with larger datasets with text, this is a much better way to handle LDA and other Gensim models from a performance point of view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "\n",
    "for text in documents:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "          for text in documents]\n",
    "\n",
    "# Create gensim dictionary object\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# Create corpus matrix\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the actual LDA model!\n",
    "Finally we initialize and assign our model to a variable object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda = models.LdaModel(\n",
    "    matutils.Sparse2Corpus(X, documents_columns=False),\n",
    "    # or use the corpus object created with the dictionary in the previous frame!\n",
    "    # corpus, \n",
    "    num_topics  =  3,\n",
    "    passes      =  20,\n",
    "    id2word     =  vocab\n",
    "    # or use the gensim dictionary object!\n",
    "    # id2word     =  dictionary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Ok great, what now?!\n",
    "Well let's look at the topics already!  These are the topics overall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.079*mother + 0.079*brother + 0.079*pressure + 0.078*perform + 0.078*better'),\n",
       " (1,\n",
       "  u'0.090*driving + 0.051*increased + 0.051*experts + 0.051*suggest + 0.051*cause'),\n",
       " (2, u'0.139*brocolli + 0.139*good + 0.097*health + 0.097*eat + 0.056*likes')]"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(num_topics=3, num_words=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how each document scored per topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.44706669943799121), (1, 0.24550135159463513), (2, 0.30743194896737369)]"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_document_topics(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make it pretty!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets come up with some high level labels\n",
    "This is the subjective part of LDA.  What do the word probabilties that represent topics mean?  Let's make some up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics_labels = {\n",
    "   0: \"Family Stress\",\n",
    "   1: \"Driving\",\n",
    "   2: \"Food\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "document_id  topic        \n",
       "0            Driving          0.245502\n",
       "             Family Stress    0.447065\n",
       "             Food             0.307433\n",
       "1            Driving          0.376048\n",
       "             Family Stress    0.396879\n",
       "             Food             0.227073\n",
       "2            Driving          0.418195\n",
       "             Family Stress    0.424889\n",
       "             Food             0.156916\n",
       "3            Driving          0.244594\n",
       "             Family Stress    0.484555\n",
       "             Food             0.270851\n",
       "4            Driving          0.385586\n",
       "             Family Stress    0.359411\n",
       "             Food             0.255003\n",
       "Name: probability, dtype: float64"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topics = [lda.get_document_topics(doc) for doc in corpus]\n",
    "\n",
    "topic_data = []\n",
    "\n",
    "for document_id, topics in enumerate(doc_topics):\n",
    "    \n",
    "    document_topics = []\n",
    "    \n",
    "    for topic, probability in topics:\n",
    "       \n",
    "        topic_data.append({\n",
    "            'document_id':  document_id,\n",
    "            'topic_id':     topic,\n",
    "            'topic':        topics_labels[topic],\n",
    "            'probability':  probability\n",
    "        })\n",
    "\n",
    "topics_df = pd.DataFrame(topic_data)\n",
    "topics_df.pivot_table(values=\"probability\", index=[\"document_id\", \"topic\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So what now!?\n",
    "\n",
    "Well, this is a very basic example.  LDA typically doesn't perform well on very small datasets.  It can be useful to see how it works and to implement, but you should try to see how it behaves on your own.  Finding the optimal number of topics can be tricky.\n",
    "\n",
    "Generally, you should consider:\n",
    "- How well topics are applied to documents overall\n",
    "- The strength of topics overall, to all documents\n",
    "- Improving preprocessing such as stopword removal\n",
    "- Building a nice web interface to explore your documents (see: [LDAExplorer](https://github.com/dyerrington/LDAExplorer), and [pyLDAvis](https://github.com/bmabey/pyLDAvis/blob/master/README.rst))\n",
    "\n",
    "These general guidelines should help you tune your hyperparameter **K** for number of topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (?? ~ Mins) Independant Practice\n",
    "It's time to try this on your own or with a group!\n",
    "\n",
    "For this practice, you will be working with the 20 newsgroup dataset from skelarn.datasets, which has a collection of newsgroup discussions.  \n",
    "\n",
    "### Load up the 20 newsgroup dataset from sklearn.datasets\n",
    "This could take a little while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "news = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['description', 'DESCR', 'filenames', 'target_names', 'data', 'target']"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>/Users/davidyerrington/scikit_learn_data/20new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>/Users/davidyerrington/scikit_learn_data/20new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>/Users/davidyerrington/scikit_learn_data/20new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>/Users/davidyerrington/scikit_learn_data/20new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>/Users/davidyerrington/scikit_learn_data/20new...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...   \n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...   \n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...   \n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...   \n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...   \n",
       "\n",
       "                                                file  \n",
       "0  /Users/davidyerrington/scikit_learn_data/20new...  \n",
       "1  /Users/davidyerrington/scikit_learn_data/20new...  \n",
       "2  /Users/davidyerrington/scikit_learn_data/20new...  \n",
       "3  /Users/davidyerrington/scikit_learn_data/20new...  \n",
       "4  /Users/davidyerrington/scikit_learn_data/20new...  "
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Allow me to setup a dataframe\n",
    "news_df = pd.DataFrame(news['data'], columns=[\"text\"])\n",
    "news_df['file'] = news['filenames']\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pull out the newsgroup name from the \"file\" column, assign to new feature called \"newsgroup\"\n",
    "Within the filepath variable, contains a newsgroup string that will be useful for filtering.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/davidyerrington/scikit_learn_data/20news_home/20news-bydate-train/rec.autos/102994'"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is an example of a single filepath.  The newsgroup this belongs to is \"rec.autos\".\n",
    "news_df['file'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Select a single newsgroup topic to setup and perform LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examine the topics that are found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adjust your number of topics parameter\n",
    "A strong clue to get the K parameter just right, is to see how word probabilities overlap.  Sometimes you'll see duplicate topics occur so you should reduce the number until they no longer overlap.  There are some downsides to this approach but it's a quick and easy first pass until you can take a deeper look at everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Of the topics, how are they distributed across your documents?\n",
    "Plot a histogram of a few of the topics to see how they are spread.  Do any dominate?  Are few represented?\n",
    "\n",
    "One of the toughest questions to examine is how relevent the documents content is to the actual topics.  The latent characteristics may be present, but not understood fully.  There is a real risk of going down the rabbit hole and tweaking the model excessively (remember, 4+ months were spent iterating on Rapstats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Can you further clean your newsgroup text?\n",
    "\n",
    "Look at those blasted subject headers and crap in the first lines of the messages.  Can you think of any ways to get rid of some of the more common terms?  Hint:  Remove items that only occur once, or too frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Implement TFIDF vectorizer instead of count vectorizer.\n",
    "\n",
    "How does this compare?  Does this improve the quality of results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
