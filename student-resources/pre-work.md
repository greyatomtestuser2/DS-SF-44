# DS-SF-44 Pre-work Summary

Class | Pre-work (be able to...)
--- | ---  
3/20: Intro to Data Science | - Define basic data types used in object-oriented programming <br />  - Recall the Python syntax for lists, dictionaries, and functions <br /> - Create files and navigate directories using the command line interface
3/22: Numpy & Pandas | - Can create and open an Jupyter Notebook <br /> - Completed the Python pre-work
3/27: Statistics Fundamentals I | 
3/29: Statistics Fundamentals II | - Explain the difference between variance and bias <br /> - Use descriptive statistics to understand your data
4/3: Flex Session |
4/5: Introduction to Linear Regression | - Effectively show correlations between an independent variable x and a dependent variable y  <br /> - Be familiar with the get_dummies function in pandas  <br />  -Understand the difference between vectors, matrices, Series, and DataFrames  <br /> - Understand the concepts of outliers and distance  <br /> - Be able to interpret p values and confidence intervals
4/10: Evaluating Model Fit | - Understand goodness of fit (r-squared) <br /> - Measure statistical significance of features <br /> - Recall what a residual is <br /> - Implement a sklearn estimator to predict a target variable
4/12: Intro to classification | - Understand how to optimize for error in a model <br /> - Understand the concept of iteration to solve problems <br /> - Measure basic probability
4/17: Intro to Logistic Regression | - Implement a linear model (LinearRegression) with sklearn or statsmodels <br /> - Define the concept of coefficients <br /> - Recall metrics for accuracy and misclassification <br /> - Recall the differences between L1 and L2 regularization
4/19: Communicating the Results of Logistic Regression  | - Understand results from a confusion matrix, and measure true positive rate and false positive rate <br /> - Create and interpret results from a binary classification problem <br /> - Know what a decision line is in logistic regression
4/24: Flex Session  | - Use sckit-learn to fit models <br /> - Use seaborn to create plots <br /> - Use pandas to load datasets
4/26: Decision Trees | - Use seaborn to create plots <br /> - Knowledge of a bootstrap sample <br /> - Explain the concepts of cross-validation, logistic regression, and overfitting <br /> - Know how to build and evaluate some classification model in sckit-learn using cross-validation and AUC
5/1: NLP with Classification | - Experience with sckit-learn classifiers, specifically Random Forests and Decision trees <br /> - Install spacy with pip install spacy (or use Anaconda) <br /> - Run the spacy download data command
5/3: Dimensionality Reduction | - Install gensim with pip install gensim <br /> - Recall and apply unsupervised learning techniques <br /> - Recall probability distributions, specifically discrete multinomial distributions <br /> - Recall NLP essentials, including experience with spacy <br /> - BONUS: If you are interested in accessing the Twitter API, you'll need to [setup Twitter API credentials](./twitter-instructions.md)
5/8: Time-series Data | - Load data with Pandas, plotting data with Seaborn <br /> - Define and explain the concept of correlation
5/10: Models with Time-series Data | - Prior definition and Python functions for moving averages and autocorrelation <br /> - Prior exposure to linear regression with discussion of coefficients and residuals <br /> - pip install statsmodels (should be included with Anaconda)
5/15: The Value of Data-bases | There will be multiple ways to run the exercises: <br /> - Using Postgres Exercises <br /> - Setting up local Postgres <br /> - Install Postgres: if brew is installed, this should be as simple as brew install postgres <br /> - Using Wagon: Create an account at https://www.wagonhq.com/ and download the software
5/17: Next Steps with Data Science | - Define the data science workflow <br /> - Apply course information to your own professional interests
5/22: Deep Learning | - Understand Logistic Regression and link functions <br /> - Be familiar with training and testing classifiers and regressors
5/24: Final Presentations!!! |
